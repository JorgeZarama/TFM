{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5692decf-f4bc-4e4a-a2ad-512bf2771991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo .pkl completo\n",
    "pkl_file = 'df_withcorona_clean_2_with_proba_opti_and_hour.pkl'\n",
    "df = pd.read_pickle(pkl_file)\n",
    "\n",
    "# Guardar como CSV\n",
    "df.to_csv('df_withcorona_clean_2_with_proba_opti_and_hour.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38800dfa-1548-4705-986a-4b150405b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV grande\n",
    "file_path = 'df_withcorona_clean_2_with_proba_opti_and_hour.csv'\n",
    "\n",
    "# Define el tamaño del chunk en términos de número de filas\n",
    "chunk_size = 10000  # Ajusta este número según lo necesites\n",
    "\n",
    "# Inicializa una lista para acumular los chunks filtrados\n",
    "filtered_chunks = []\n",
    "\n",
    "# Itera sobre el archivo CSV en chunks\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    #print(f\"Procesando chunk {i+1}\")\n",
    "    \n",
    "    # Filtrar los registros que tienen \"TMS\" en la columna 'ticker'\n",
    "    filtered_chunk = chunk[chunk['ticker'] == 'ASML']\n",
    "    \n",
    "    # Muestra 10 ejemplos de filas filtradas (si existen)\n",
    "    if not filtered_chunk.empty:\n",
    "        #print(\"Ejemplos de filas filtradas en este chunk:\")\n",
    "        #print(filtered_chunk.head(10))\n",
    "        \n",
    "        # Acumular los chunks filtrados\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenar todos los chunks filtrados en un nuevo DataFrame\n",
    "filtered_df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar el nuevo DataFrame filtrado en un archivo CSV\n",
    "filtered_df.to_csv('filtered_ASML_records2.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0edb06a8-dff8-42b0-8483-b3e3e2de4440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id_msg</th>\n",
       "      <th>msg</th>\n",
       "      <th>date</th>\n",
       "      <th>sent</th>\n",
       "      <th>id_user</th>\n",
       "      <th>foll</th>\n",
       "      <th>ideas</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sent_new</th>\n",
       "      <th>sent_merged</th>\n",
       "      <th>sent_new_noros</th>\n",
       "      <th>bullish_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASML</td>\n",
       "      <td>97662126</td>\n",
       "      <td>asml holding n.v. upgraded by bnp paribas to o...</td>\n",
       "      <td>2017-10-12 19:46:48+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>284225</td>\n",
       "      <td>6090</td>\n",
       "      <td>570035</td>\n",
       "      <td>asml holding nv upgrade by bnp paribas to outp...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASML</td>\n",
       "      <td>97664470</td>\n",
       "      <td>$asml bnp paribas upgrades to outperform from ...</td>\n",
       "      <td>2017-10-12 19:56:38+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>894342</td>\n",
       "      <td>6572</td>\n",
       "      <td>169825</td>\n",
       "      <td>bnp paribas upgrade to outperform from neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASML</td>\n",
       "      <td>97666148</td>\n",
       "      <td>recap 10/12\\n+pos comments: $nav $amd $asml $n...</td>\n",
       "      <td>2017-10-12 20:03:15+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>348830</td>\n",
       "      <td>191496</td>\n",
       "      <td>79599</td>\n",
       "      <td>recap pos comment neg comment</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASML</td>\n",
       "      <td>97670621</td>\n",
       "      <td>$amat $asml $brks $klac $lrcx $mu $smh $soxx $...</td>\n",
       "      <td>2017-10-12 20:24:39+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1063472</td>\n",
       "      <td>57</td>\n",
       "      <td>2405</td>\n",
       "      <td>hope you didnt get shake out samsung report to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASML</td>\n",
       "      <td>97681761</td>\n",
       "      <td>scan results - new 52 week closing high today:...</td>\n",
       "      <td>2017-10-12 21:28:15+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>356080</td>\n",
       "      <td>38651</td>\n",
       "      <td>118902</td>\n",
       "      <td>scan result new week close high today</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>ASML</td>\n",
       "      <td>200956174</td>\n",
       "      <td>$asml huge stimulus package just announced for...</td>\n",
       "      <td>2020-03-17 18:18:55+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>476261</td>\n",
       "      <td>5</td>\n",
       "      <td>307</td>\n",
       "      <td>huge stimulus package just announce for compan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>ASML</td>\n",
       "      <td>201385584</td>\n",
       "      <td>four stocks showing adult strength in pre-mark...</td>\n",
       "      <td>2020-03-19 13:08:37+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>234699</td>\n",
       "      <td>182</td>\n",
       "      <td>2718</td>\n",
       "      <td>stock show adult strength in pre market trading</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>ASML</td>\n",
       "      <td>201623391</td>\n",
       "      <td>global stocks rise as governments and central ...</td>\n",
       "      <td>2020-03-20 10:19:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2762379</td>\n",
       "      <td>2171</td>\n",
       "      <td>279736</td>\n",
       "      <td>global stock rise as government and central ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>ASML</td>\n",
       "      <td>201674208</td>\n",
       "      <td>$asml wells fargo maintains to overweight : pt...</td>\n",
       "      <td>2020-03-20 14:15:35+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>835250</td>\n",
       "      <td>1397</td>\n",
       "      <td>42253</td>\n",
       "      <td>wells fargo maintain to overweight pt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>ASML</td>\n",
       "      <td>201677212</td>\n",
       "      <td>$asml monster move coming</td>\n",
       "      <td>2020-03-20 14:24:22+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>488560</td>\n",
       "      <td>6050</td>\n",
       "      <td>12834</td>\n",
       "      <td>monster move come</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2587 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker     id_msg                                                msg  \\\n",
       "0      ASML   97662126  asml holding n.v. upgraded by bnp paribas to o...   \n",
       "1      ASML   97664470  $asml bnp paribas upgrades to outperform from ...   \n",
       "2      ASML   97666148  recap 10/12\\n+pos comments: $nav $amd $asml $n...   \n",
       "3      ASML   97670621  $amat $asml $brks $klac $lrcx $mu $smh $soxx $...   \n",
       "4      ASML   97681761  scan results - new 52 week closing high today:...   \n",
       "...     ...        ...                                                ...   \n",
       "2582   ASML  200956174  $asml huge stimulus package just announced for...   \n",
       "2583   ASML  201385584  four stocks showing adult strength in pre-mark...   \n",
       "2584   ASML  201623391  global stocks rise as governments and central ...   \n",
       "2585   ASML  201674208  $asml wells fargo maintains to overweight : pt...   \n",
       "2586   ASML  201677212                          $asml monster move coming   \n",
       "\n",
       "                           date  sent  id_user    foll   ideas  \\\n",
       "0     2017-10-12 19:46:48+00:00     0   284225    6090  570035   \n",
       "1     2017-10-12 19:56:38+00:00     0   894342    6572  169825   \n",
       "2     2017-10-12 20:03:15+00:00     0   348830  191496   79599   \n",
       "3     2017-10-12 20:24:39+00:00     1  1063472      57    2405   \n",
       "4     2017-10-12 21:28:15+00:00     0   356080   38651  118902   \n",
       "...                         ...   ...      ...     ...     ...   \n",
       "2582  2020-03-17 18:18:55+00:00     0   476261       5     307   \n",
       "2583  2020-03-19 13:08:37+00:00     0   234699     182    2718   \n",
       "2584  2020-03-20 10:19:41+00:00     0  2762379    2171  279736   \n",
       "2585  2020-03-20 14:15:35+00:00     0   835250    1397   42253   \n",
       "2586  2020-03-20 14:24:22+00:00     1   488560    6050   12834   \n",
       "\n",
       "                                             clean_text  sent_new  \\\n",
       "0     asml holding nv upgrade by bnp paribas to outp...         1   \n",
       "1        bnp paribas upgrade to outperform from neutral         1   \n",
       "2                         recap pos comment neg comment        -1   \n",
       "3     hope you didnt get shake out samsung report to...         1   \n",
       "4                 scan result new week close high today         1   \n",
       "...                                                 ...       ...   \n",
       "2582  huge stimulus package just announce for compan...         1   \n",
       "2583    stock show adult strength in pre market trading         1   \n",
       "2584  global stock rise as government and central ba...         0   \n",
       "2585              wells fargo maintain to overweight pt         1   \n",
       "2586                                  monster move come         1   \n",
       "\n",
       "      sent_merged  sent_new_noros  bullish_proba  \n",
       "0               1               1       0.997899  \n",
       "1               1               1       0.984070  \n",
       "2               0               0       0.537231  \n",
       "3               1               1       0.983556  \n",
       "4               1               1       0.971782  \n",
       "...           ...             ...            ...  \n",
       "2582            1               1       0.873428  \n",
       "2583            1               1       0.960049  \n",
       "2584            1               1       0.885042  \n",
       "2585            1               1       0.865710  \n",
       "2586            1               1       0.992075  \n",
       "\n",
       "[2587 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b26f78b-aad6-4730-8df4-ee931713b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV grande\n",
    "file_path = 'df_withcorona_clean_2_with_proba_opti_and_hour.csv'\n",
    "\n",
    "# Define el tamaño del chunk en términos de número de filas\n",
    "chunk_size = 10000  # Ajusta este número según lo necesites\n",
    "\n",
    "# Inicializa una lista para acumular los chunks filtrados\n",
    "filtered_chunks = []\n",
    "\n",
    "# Itera sobre el archivo CSV en chunks\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    #print(f\"Procesando chunk {i+1}\")\n",
    "    \n",
    "    # Filtrar los registros que tienen \"TMS\" en la columna 'ticker'\n",
    "    filtered_chunk = chunk[chunk['ticker'] == 'GOOGL']\n",
    "    \n",
    "    # Muestra 10 ejemplos de filas filtradas (si existen)\n",
    "    if not filtered_chunk.empty:\n",
    "        #print(\"Ejemplos de filas filtradas en este chunk:\")\n",
    "        #print(filtered_chunk.head(10))\n",
    "        \n",
    "        # Acumular los chunks filtrados\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenar todos los chunks filtrados en un nuevo DataFrame\n",
    "filtered_df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar el nuevo DataFrame filtrado en un archivo CSV\n",
    "filtered_df.to_csv('filtered_GOOGL_records2.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6927d778-d9e1-4bba-9ae4-c58117091a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id_msg</th>\n",
       "      <th>msg</th>\n",
       "      <th>date</th>\n",
       "      <th>sent</th>\n",
       "      <th>id_user</th>\n",
       "      <th>foll</th>\n",
       "      <th>ideas</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sent_new</th>\n",
       "      <th>sent_merged</th>\n",
       "      <th>sent_new_noros</th>\n",
       "      <th>bullish_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97639203</td>\n",
       "      <td>$amd any advantages to $nvda, $tsla, $msft, or...</td>\n",
       "      <td>2017-10-12 17:53:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>302371</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>any advantage to or absorb them</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97640632</td>\n",
       "      <td>some super winning moves right now and while t...</td>\n",
       "      <td>2017-10-12 18:00:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>23658</td>\n",
       "      <td>66055</td>\n",
       "      <td>13562</td>\n",
       "      <td>some super win move right now and while they b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97644742</td>\n",
       "      <td>10.12.17 elliott wave chart updates for f.a.n....</td>\n",
       "      <td>2017-10-12 18:20:26+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>43523</td>\n",
       "      <td>581</td>\n",
       "      <td>7610</td>\n",
       "      <td>elliott wave chart update for fang</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97648064</td>\n",
       "      <td>here’s what 203 estimize analysts believe $goo...</td>\n",
       "      <td>2017-10-12 18:37:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>727510</td>\n",
       "      <td>5325</td>\n",
       "      <td>1380224</td>\n",
       "      <td>here be what estimize analyst believe will rep...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97648456</td>\n",
       "      <td>$googl my number one long for a long time and ...</td>\n",
       "      <td>2017-10-12 18:39:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>260080</td>\n",
       "      <td>89</td>\n",
       "      <td>10003</td>\n",
       "      <td>my number long for long time and have have pri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77076</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>202040495</td>\n",
       "      <td>3 cash-rich stocks to buy during the coronavir...</td>\n",
       "      <td>2020-03-23 04:41:54+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>257806</td>\n",
       "      <td>83115</td>\n",
       "      <td>44422</td>\n",
       "      <td>cash rich stock to buy during the coronavirus ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77077</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>202043106</td>\n",
       "      <td>$googl $goog $fb $nflx $uber on point! 18,300 ...</td>\n",
       "      <td>2020-03-23 05:26:38+00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>456039</td>\n",
       "      <td>237</td>\n",
       "      <td>4749</td>\n",
       "      <td>on point have be breach on the future market i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77078</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>202050747</td>\n",
       "      <td>$googl sayonara. \\nhype is over.</td>\n",
       "      <td>2020-03-23 08:38:38+00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>1165200</td>\n",
       "      <td>579</td>\n",
       "      <td>13529</td>\n",
       "      <td>sayonara hype be over</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.173250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77079</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>202052513</td>\n",
       "      <td>#cisco pledges $225m to fight #global coronavi...</td>\n",
       "      <td>2020-03-23 09:20:13+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>296805</td>\n",
       "      <td>28407</td>\n",
       "      <td>241470</td>\n",
       "      <td>cisco pledge to fight global coronavirus pande...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77080</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>202056635</td>\n",
       "      <td>$spy $googl $bac $dust all looking like red</td>\n",
       "      <td>2020-03-23 10:38:14+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>820339</td>\n",
       "      <td>1890</td>\n",
       "      <td>14921</td>\n",
       "      <td>all look like red</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.466627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77081 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker     id_msg                                                msg  \\\n",
       "0      GOOGL   97639203  $amd any advantages to $nvda, $tsla, $msft, or...   \n",
       "1      GOOGL   97640632  some super winning moves right now and while t...   \n",
       "2      GOOGL   97644742  10.12.17 elliott wave chart updates for f.a.n....   \n",
       "3      GOOGL   97648064  here’s what 203 estimize analysts believe $goo...   \n",
       "4      GOOGL   97648456  $googl my number one long for a long time and ...   \n",
       "...      ...        ...                                                ...   \n",
       "77076  GOOGL  202040495  3 cash-rich stocks to buy during the coronavir...   \n",
       "77077  GOOGL  202043106  $googl $goog $fb $nflx $uber on point! 18,300 ...   \n",
       "77078  GOOGL  202050747                   $googl sayonara. \\nhype is over.   \n",
       "77079  GOOGL  202052513  #cisco pledges $225m to fight #global coronavi...   \n",
       "77080  GOOGL  202056635        $spy $googl $bac $dust all looking like red   \n",
       "\n",
       "                            date  sent  id_user   foll    ideas  \\\n",
       "0      2017-10-12 17:53:54+00:00     1   302371      0       64   \n",
       "1      2017-10-12 18:00:41+00:00     0    23658  66055    13562   \n",
       "2      2017-10-12 18:20:26+00:00     0    43523    581     7610   \n",
       "3      2017-10-12 18:37:11+00:00     0   727510   5325  1380224   \n",
       "4      2017-10-12 18:39:16+00:00     0   260080     89    10003   \n",
       "...                          ...   ...      ...    ...      ...   \n",
       "77076  2020-03-23 04:41:54+00:00     0   257806  83115    44422   \n",
       "77077  2020-03-23 05:26:38+00:00    -1   456039    237     4749   \n",
       "77078  2020-03-23 08:38:38+00:00    -1  1165200    579    13529   \n",
       "77079  2020-03-23 09:20:13+00:00     0   296805  28407   241470   \n",
       "77080  2020-03-23 10:38:14+00:00     0   820339   1890    14921   \n",
       "\n",
       "                                              clean_text  sent_new  \\\n",
       "0                        any advantage to or absorb them         1   \n",
       "1      some super win move right now and while they b...         1   \n",
       "2                     elliott wave chart update for fang        -1   \n",
       "3      here be what estimize analyst believe will rep...         1   \n",
       "4      my number long for long time and have have pri...         1   \n",
       "...                                                  ...       ...   \n",
       "77076  cash rich stock to buy during the coronavirus ...         0   \n",
       "77077  on point have be breach on the future market i...        -1   \n",
       "77078                              sayonara hype be over        -1   \n",
       "77079  cisco pledge to fight global coronavirus pande...         1   \n",
       "77080                                  all look like red        -1   \n",
       "\n",
       "       sent_merged  sent_new_noros  bullish_proba  \n",
       "0                1               1       0.960898  \n",
       "1                1               1       0.968377  \n",
       "2                0               0       0.642861  \n",
       "3                1               1       0.937859  \n",
       "4                1               1       0.906699  \n",
       "...            ...             ...            ...  \n",
       "77076            1               1       0.836143  \n",
       "77077           -1               0       0.617062  \n",
       "77078           -1              -1       0.173250  \n",
       "77079            1               1       0.934952  \n",
       "77080           -1              -1       0.466627  \n",
       "\n",
       "[77081 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8434fd55-32f9-4b95-92a6-18d6a92e8e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV grande\n",
    "file_path = 'df_withcorona_clean_2_with_proba_opti_and_hour.csv'\n",
    "\n",
    "# Define el tamaño del chunk en términos de número de filas\n",
    "chunk_size = 10000  # Ajusta este número según lo necesites\n",
    "\n",
    "# Inicializa una lista para acumular los chunks filtrados\n",
    "filtered_chunks = []\n",
    "\n",
    "# Itera sobre el archivo CSV en chunks\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    #print(f\"Procesando chunk {i+1}\")\n",
    "    \n",
    "    # Filtrar los registros que tienen \"TMS\" en la columna 'ticker'\n",
    "    filtered_chunk = chunk[chunk['ticker'] == 'LRCX']\n",
    "    \n",
    "    # Muestra 10 ejemplos de filas filtradas (si existen)\n",
    "    if not filtered_chunk.empty:\n",
    "        #print(\"Ejemplos de filas filtradas en este chunk:\")\n",
    "        #print(filtered_chunk.head(10))\n",
    "        \n",
    "        # Acumular los chunks filtrados\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenar todos los chunks filtrados en un nuevo DataFrame\n",
    "filtered_df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar el nuevo DataFrame filtrado en un archivo CSV\n",
    "filtered_df.to_csv('filtered_LRCX_records2.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c432e9c2-a4d1-4a8c-8222-23c57eb19b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id_msg</th>\n",
       "      <th>msg</th>\n",
       "      <th>date</th>\n",
       "      <th>sent</th>\n",
       "      <th>id_user</th>\n",
       "      <th>foll</th>\n",
       "      <th>ideas</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sent_new</th>\n",
       "      <th>sent_merged</th>\n",
       "      <th>sent_new_noros</th>\n",
       "      <th>bullish_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>97640632</td>\n",
       "      <td>some super winning moves right now and while t...</td>\n",
       "      <td>2017-10-12 18:00:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>23658</td>\n",
       "      <td>66057</td>\n",
       "      <td>13568</td>\n",
       "      <td>some super win move right now and while they b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>97640806</td>\n",
       "      <td>@danzanger $lrcx and $bidu really surpriced me...</td>\n",
       "      <td>2017-10-12 18:01:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>515233</td>\n",
       "      <td>893</td>\n",
       "      <td>12954</td>\n",
       "      <td>and really surprice me in particular lam resea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>97644896</td>\n",
       "      <td>$mksi $slab $snps $lrcx $uctt $ichr $nvmi $for...</td>\n",
       "      <td>2017-10-12 18:21:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>433942</td>\n",
       "      <td>3926</td>\n",
       "      <td>77617</td>\n",
       "      <td>we need semis but we need earning first</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>97669793</td>\n",
       "      <td>nvidia scores price-target hike; chip-gear fir...</td>\n",
       "      <td>2017-10-12 20:20:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1134530</td>\n",
       "      <td>47</td>\n",
       "      <td>912</td>\n",
       "      <td>nvidia scores price target hike chip gear firm...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>97670621</td>\n",
       "      <td>$amat $asml $brks $klac $lrcx $mu $smh $soxx $...</td>\n",
       "      <td>2017-10-12 20:24:39+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1063472</td>\n",
       "      <td>56</td>\n",
       "      <td>2405</td>\n",
       "      <td>hope you didnt get shake out samsung report to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>201971555</td>\n",
       "      <td>*update 3/28/18 post* $lrcx second parabolic a...</td>\n",
       "      <td>2020-03-22 18:44:46+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>16911</td>\n",
       "      <td>64787</td>\n",
       "      <td>22177</td>\n",
       "      <td>update post second parabolic arc esix</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>201981585</td>\n",
       "      <td>$lrcx governor cuomo warns lockdown could last...</td>\n",
       "      <td>2020-03-22 20:28:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2937872</td>\n",
       "      <td>10</td>\n",
       "      <td>706</td>\n",
       "      <td>governor cuomo warn lockdown could last month</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25724</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>201993202</td>\n",
       "      <td>your daily news digest for lam research corpor...</td>\n",
       "      <td>2020-03-22 22:13:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>732840</td>\n",
       "      <td>136</td>\n",
       "      <td>21209</td>\n",
       "      <td>your daily news digest for lam research corpor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25725</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>202046139</td>\n",
       "      <td>$lrcx looking to add this at 150.</td>\n",
       "      <td>2020-03-23 06:43:06+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1250948</td>\n",
       "      <td>11</td>\n",
       "      <td>829</td>\n",
       "      <td>look to add this at</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25726</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>202046654</td>\n",
       "      <td>an altman-z score of 5.49 indicates that $lrcx...</td>\n",
       "      <td>2020-03-23 06:56:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>47688</td>\n",
       "      <td>14689</td>\n",
       "      <td>842994</td>\n",
       "      <td>an altman score of indicate that be not in any...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.168505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25727 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker     id_msg                                                msg  \\\n",
       "0       LRCX   97640632  some super winning moves right now and while t...   \n",
       "1       LRCX   97640806  @danzanger $lrcx and $bidu really surpriced me...   \n",
       "2       LRCX   97644896  $mksi $slab $snps $lrcx $uctt $ichr $nvmi $for...   \n",
       "3       LRCX   97669793  nvidia scores price-target hike; chip-gear fir...   \n",
       "4       LRCX   97670621  $amat $asml $brks $klac $lrcx $mu $smh $soxx $...   \n",
       "...      ...        ...                                                ...   \n",
       "25722   LRCX  201971555  *update 3/28/18 post* $lrcx second parabolic a...   \n",
       "25723   LRCX  201981585  $lrcx governor cuomo warns lockdown could last...   \n",
       "25724   LRCX  201993202  your daily news digest for lam research corpor...   \n",
       "25725   LRCX  202046139                  $lrcx looking to add this at 150.   \n",
       "25726   LRCX  202046654  an altman-z score of 5.49 indicates that $lrcx...   \n",
       "\n",
       "                            date  sent  id_user   foll   ideas  \\\n",
       "0      2017-10-12 18:00:41+00:00     0    23658  66057   13568   \n",
       "1      2017-10-12 18:01:30+00:00     0   515233    893   12954   \n",
       "2      2017-10-12 18:21:11+00:00     0   433942   3926   77617   \n",
       "3      2017-10-12 20:20:11+00:00     0  1134530     47     912   \n",
       "4      2017-10-12 20:24:39+00:00     1  1063472     56    2405   \n",
       "...                          ...   ...      ...    ...     ...   \n",
       "25722  2020-03-22 18:44:46+00:00     0    16911  64787   22177   \n",
       "25723  2020-03-22 20:28:40+00:00     0  2937872     10     706   \n",
       "25724  2020-03-22 22:13:47+00:00     0   732840    136   21209   \n",
       "25725  2020-03-23 06:43:06+00:00     1  1250948     11     829   \n",
       "25726  2020-03-23 06:56:00+00:00     0    47688  14689  842994   \n",
       "\n",
       "                                              clean_text  sent_new  \\\n",
       "0      some super win move right now and while they b...         1   \n",
       "1      and really surprice me in particular lam resea...         1   \n",
       "2                we need semis but we need earning first         1   \n",
       "3      nvidia scores price target hike chip gear firm...         1   \n",
       "4      hope you didnt get shake out samsung report to...         1   \n",
       "...                                                  ...       ...   \n",
       "25722              update post second parabolic arc esix         0   \n",
       "25723      governor cuomo warn lockdown could last month        -1   \n",
       "25724  your daily news digest for lam research corpor...         1   \n",
       "25725                                look to add this at         1   \n",
       "25726  an altman score of indicate that be not in any...        -1   \n",
       "\n",
       "       sent_merged  sent_new_noros  bullish_proba  \n",
       "0                1               1       0.968377  \n",
       "1                1               1       0.957617  \n",
       "2                1               1       0.977520  \n",
       "3                1               1       0.983624  \n",
       "4                1               1       0.983556  \n",
       "...            ...             ...            ...  \n",
       "25722            1               1       0.846719  \n",
       "25723            0               0       0.549299  \n",
       "25724            1               1       0.953619  \n",
       "25725            1               1       0.965037  \n",
       "25726           -1              -1       0.168505  \n",
       "\n",
       "[25727 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab64a5b-6208-421e-a60c-f7458f92ebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV grande\n",
    "file_path = 'df_withcorona_clean_2_with_proba_opti_and_hour.csv'\n",
    "\n",
    "# Define el tamaño del chunk en términos de número de filas\n",
    "chunk_size = 10000  # Ajusta este número según lo necesites\n",
    "\n",
    "# Inicializa una lista para acumular los chunks filtrados\n",
    "filtered_chunks = []\n",
    "\n",
    "# Itera sobre el archivo CSV en chunks\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    #print(f\"Procesando chunk {i+1}\")\n",
    "    \n",
    "    # Filtrar los registros que tienen \"TMS\" en la columna 'ticker'\n",
    "    filtered_chunk = chunk[chunk['ticker'] == 'TMS']\n",
    "    \n",
    "    # Muestra 10 ejemplos de filas filtradas (si existen)\n",
    "    if not filtered_chunk.empty:\n",
    "        #print(\"Ejemplos de filas filtradas en este chunk:\")\n",
    "        #print(filtered_chunk.head(10))\n",
    "        \n",
    "        # Acumular los chunks filtrados\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenar todos los chunks filtrados en un nuevo DataFrame\n",
    "filtered_df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar el nuevo DataFrame filtrado en un archivo CSV\n",
    "filtered_df.to_csv('filtered_TMS_records2.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Los registros filtrados se han guardado en 'filtered_asml_records.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3caf9164-e3e8-4656-90d8-6682305dbcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id_msg</th>\n",
       "      <th>msg</th>\n",
       "      <th>date</th>\n",
       "      <th>sent</th>\n",
       "      <th>id_user</th>\n",
       "      <th>foll</th>\n",
       "      <th>ideas</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sent_new</th>\n",
       "      <th>sent_merged</th>\n",
       "      <th>sent_new_noros</th>\n",
       "      <th>bullish_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TMS</td>\n",
       "      <td>121825888</td>\n",
       "      <td>@bullishbynature administration is clearly not...</td>\n",
       "      <td>2018-05-01 14:42:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>354309</td>\n",
       "      <td>151</td>\n",
       "      <td>14635</td>\n",
       "      <td>administration be clearly not totally oppose a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TMS</td>\n",
       "      <td>132056292</td>\n",
       "      <td>$x qtr will look more like $nue and much less ...</td>\n",
       "      <td>2018-07-31 14:33:55+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>301323</td>\n",
       "      <td>37</td>\n",
       "      <td>2007</td>\n",
       "      <td>qtr will look more like and much less like and...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TMS</td>\n",
       "      <td>132081329</td>\n",
       "      <td>$x $nue $aks $tms this is spot on. x is six ti...</td>\n",
       "      <td>2018-07-31 16:28:44+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>283547</td>\n",
       "      <td>28</td>\n",
       "      <td>2685</td>\n",
       "      <td>this be spot on be time large than ks and whol...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMS</td>\n",
       "      <td>150190635</td>\n",
       "      <td>amd unveils new high-end gpu and details upcom...</td>\n",
       "      <td>2019-01-09 22:02:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>962572</td>\n",
       "      <td>37406</td>\n",
       "      <td>91959</td>\n",
       "      <td>amd unveil new high end gpu and detail upcome ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMS</td>\n",
       "      <td>161231182</td>\n",
       "      <td>$tms</td>\n",
       "      <td>2019-04-18 19:04:27+00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>1135115</td>\n",
       "      <td>168</td>\n",
       "      <td>3760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker     id_msg                                                msg  \\\n",
       "0    TMS  121825888  @bullishbynature administration is clearly not...   \n",
       "1    TMS  132056292  $x qtr will look more like $nue and much less ...   \n",
       "2    TMS  132081329  $x $nue $aks $tms this is spot on. x is six ti...   \n",
       "3    TMS  150190635  amd unveils new high-end gpu and details upcom...   \n",
       "4    TMS  161231182                                               $tms   \n",
       "\n",
       "                        date  sent  id_user   foll  ideas  \\\n",
       "0  2018-05-01 14:42:27+00:00     0   354309    151  14635   \n",
       "1  2018-07-31 14:33:55+00:00     1   301323     37   2007   \n",
       "2  2018-07-31 16:28:44+00:00     0   283547     28   2685   \n",
       "3  2019-01-09 22:02:09+00:00     0   962572  37406  91959   \n",
       "4  2019-04-18 19:04:27+00:00    -1  1135115    168   3760   \n",
       "\n",
       "                                          clean_text  sent_new  sent_merged  \\\n",
       "0  administration be clearly not totally oppose a...         0            1   \n",
       "1  qtr will look more like and much less like and...        -1            1   \n",
       "2  this be spot on be time large than ks and whol...         1            1   \n",
       "3  amd unveil new high end gpu and detail upcome ...         1            1   \n",
       "4                                                NaN         0           -1   \n",
       "\n",
       "   sent_new_noros  bullish_proba  \n",
       "0               1       0.797608  \n",
       "1               0       0.680076  \n",
       "2               1       0.858959  \n",
       "3               1       0.989958  \n",
       "4               1       0.842373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(filtered_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7837adc0-4f91-40eb-a07f-4e326138ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Los registros filtrados se han guardado en 'filtered_NVDA_records.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV grande\n",
    "file_path = 'df_withcorona_clean_2_with_proba_opti_and_hour.csv'\n",
    "\n",
    "# Define el tamaño del chunk en términos de número de filas\n",
    "chunk_size = 10000  # Ajusta este número según lo necesites\n",
    "\n",
    "# Inicializa una lista para acumular los chunks filtrados\n",
    "filtered_chunks = []\n",
    "\n",
    "# Itera sobre el archivo CSV en chunks\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    #print(f\"Procesando chunk {i+1}\")\n",
    "    \n",
    "    # Filtrar los registros que tienen \"TMS\" en la columna 'ticker'\n",
    "    filtered_chunk = chunk[chunk['ticker'] == 'NVDA']\n",
    "    \n",
    "    # Muestra 10 ejemplos de filas filtradas (si existen)\n",
    "    if not filtered_chunk.empty:\n",
    "        #print(\"Ejemplos de filas filtradas en este chunk:\")\n",
    "        #print(filtered_chunk.head(10))\n",
    "        \n",
    "        # Acumular los chunks filtrados\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Concatenar todos los chunks filtrados en un nuevo DataFrame\n",
    "filtered_df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar el nuevo DataFrame filtrado en un archivo CSV\n",
    "filtered_df.to_csv('filtered_NVDA_records2.csv', index=False)\n",
    "\n",
    "print(\"Proceso completado. Los registros filtrados se han guardado en 'filtered_NVDA_records.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f286866-2622-4001-aae9-29754ef80f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750b560-5be4-47c3-b955-4eb9706998e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
